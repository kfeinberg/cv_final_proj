{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object Detection for CS1430 Project:\n",
    "\n",
    " - This notebook will works as a way to explore different methods for object detection\n",
    "\n",
    " references:\n",
    "\n",
    "https://medium.com/deepquestai/object-detection-training-preparing-your-custom-dataset-6248679f0d1d \n",
    " https://medium.com/deepquestai/train-object-detection-ai-with-6-lines-of-code-6d087063f6ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      " 11 2596k   11  303k    0     0   672k      0  0:00:03 --:--:--  0:00:03  672k\n",
      "100 2596k  100 2596k    0     0  1867k      0  0:00:01  0:00:01 --:--:-- 1869k\n"
     ]
    }
   ],
   "source": [
    "!curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pip\n",
      "  Using cached pip-22.0.4-py3-none-any.whl (2.1 MB)\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 22.0.4\n",
      "    Uninstalling pip-22.0.4:\n",
      "      Successfully uninstalled pip-22.0.4\n",
      "Successfully installed pip-22.0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts pip.exe, pip3.8.exe and pip3.exe are installed in 'C:\\Users\\mtapi\\AppData\\Local\\Programs\\Python\\Python38\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "!py get-pip.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyqt5 in c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages (5.15.6)\n",
      "Requirement already satisfied: lxml in c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages (4.8.0)\n",
      "Requirement already satisfied: PyQt5-sip<13,>=12.8 in c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages (from pyqt5) (12.10.1)\n",
      "Requirement already satisfied: PyQt5-Qt5>=5.15.2 in c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages (from pyqt5) (5.15.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyqt5 lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras==2.4.3\n",
      "  Using cached Keras-2.4.3-py2.py3-none-any.whl (36 kB)\n",
      "Collecting numpy==1.19.3\n",
      "  Using cached numpy-1.19.3-cp38-cp38-win_amd64.whl (13.3 MB)\n",
      "Requirement already satisfied: pillow==7.0.0 in c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages (7.0.0)\n",
      "Requirement already satisfied: scipy==1.4.1 in c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages (1.4.1)\n",
      "Requirement already satisfied: h5py==2.10.0 in c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages (2.10.0)\n",
      "Requirement already satisfied: matplotlib==3.3.2 in c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages (3.3.2)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages (4.5.5.64)\n",
      "Requirement already satisfied: keras-resnet==0.2.0 in c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages (from keras==2.4.3) (6.0)\n",
      "Requirement already satisfied: six in c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages (from h5py==2.10.0) (1.16.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages (from matplotlib==3.3.2) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages (from matplotlib==3.3.2) (1.3.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages (from matplotlib==3.3.2) (3.0.7)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages (from matplotlib==3.3.2) (2021.10.8)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages (from matplotlib==3.3.2) (2.8.2)\n",
      "Installing collected packages: numpy, keras\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.22.3\n",
      "    Uninstalling numpy-1.22.3:\n",
      "      Successfully uninstalled numpy-1.22.3\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -illow (c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -illow (c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.8.0 requires keras<2.9,>=2.8.0rc0, but you have keras 2.4.3 which is incompatible.\n",
      "tensorflow 2.8.0 requires numpy>=1.20, but you have numpy 1.19.3 which is incompatible.\n",
      "tensorflow-gpu 2.3.1 requires numpy<1.19.0,>=1.16.0, but you have numpy 1.19.3 which is incompatible.\n",
      "imageio 2.14.0 requires pillow>=8.3.2, but you have pillow 7.0.0 which is incompatible.\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Uninstalling keras-2.8.0:\n",
      "      Successfully uninstalled keras-2.8.0\n",
      "Successfully installed keras-2.4.3 numpy-1.19.3\n"
     ]
    }
   ],
   "source": [
    "!pip install keras==2.4.3 numpy==1.19.3 pillow==7.0.0 scipy==1.4.1 h5py==2.10.0 matplotlib==3.3.2 opencv-python keras-resnet==0.2.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imageai in c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages (2.1.6)\n",
      "Requirement already satisfied: scipy==1.4.1 in c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages (from imageai) (1.4.1)\n",
      "Requirement already satisfied: numpy==1.19.3 in c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages (from imageai) (1.19.3)\n",
      "Requirement already satisfied: h5py==2.10.0 in c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages (from imageai) (2.10.0)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages (from imageai) (4.5.5.64)\n",
      "Requirement already satisfied: keras-resnet==0.2.0 in c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages (from imageai) (0.2.0)\n",
      "Requirement already satisfied: matplotlib==3.3.2 in c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages (from imageai) (3.3.2)\n",
      "Requirement already satisfied: pillow==7.0.0 in c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages (from imageai) (7.0.0)\n",
      "Requirement already satisfied: keras==2.4.3 in c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages (from imageai) (2.4.3)\n",
      "Requirement already satisfied: six in c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages (from h5py==2.10.0->imageai) (1.16.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages (from keras==2.4.3->imageai) (6.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages (from matplotlib==3.3.2->imageai) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages (from matplotlib==3.3.2->imageai) (2.8.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages (from matplotlib==3.3.2->imageai) (3.0.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages (from matplotlib==3.3.2->imageai) (1.3.2)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages (from matplotlib==3.3.2->imageai) (2021.10.8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install imageai --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.4.0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -illow (c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -illow (c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading tensorflow-2.4.0-cp38-cp38-win_amd64.whl (370.7 MB)\n",
      "     -------------------------------------- 370.7/370.7 MB 2.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: google-pasta~=0.2 in c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages (from tensorflow==2.4.0) (0.2.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages (from tensorflow==2.4.0) (1.1.0)\n",
      "Requirement already satisfied: tensorboard~=2.4 in c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages (from tensorflow==2.4.0) (2.8.0)\n",
      "Requirement already satisfied: h5py~=2.10.0 in c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages (from tensorflow==2.4.0) (2.10.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages (from tensorflow==2.4.0) (3.19.3)\n",
      "Collecting tensorflow-estimator<2.5.0,>=2.4.0rc0\n",
      "  Downloading tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\n",
      "     -------------------------------------- 462.0/462.0 KB 3.2 MB/s eta 0:00:00\n",
      "Collecting grpcio~=1.32.0\n",
      "  Downloading grpcio-1.32.0-cp38-cp38-win_amd64.whl (2.6 MB)\n",
      "     ---------------------------------------- 2.6/2.6 MB 3.4 MB/s eta 0:00:00\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Using cached flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: numpy~=1.19.2 in c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages (from tensorflow==2.4.0) (1.19.3)\n",
      "Collecting six~=1.15.0\n",
      "  Using cached six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages (from tensorflow==2.4.0) (3.3.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages (from tensorflow==2.4.0) (1.6.3)\n",
      "Requirement already satisfied: gast==0.3.3 in c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages (from tensorflow==2.4.0) (0.3.3)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages (from tensorflow==2.4.0) (1.1.2)\n",
      "Collecting typing-extensions~=3.7.4\n",
      "  Using cached typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Collecting wrapt~=1.12.1\n",
      "  Using cached wrapt-1.12.1-cp38-cp38-win_amd64.whl\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages (from tensorflow==2.4.0) (0.37.1)\n",
      "Collecting absl-py~=0.10\n",
      "  Using cached absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages (from tensorboard~=2.4->tensorflow==2.4.0) (1.35.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages (from tensorboard~=2.4->tensorflow==2.4.0) (3.3.6)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages (from tensorboard~=2.4->tensorflow==2.4.0) (2.0.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages (from tensorboard~=2.4->tensorflow==2.4.0) (0.6.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages (from tensorboard~=2.4->tensorflow==2.4.0) (60.7.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages (from tensorboard~=2.4->tensorflow==2.4.0) (0.4.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages (from tensorboard~=2.4->tensorflow==2.4.0) (2.27.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages (from tensorboard~=2.4->tensorflow==2.4.0) (1.8.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (4.2.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.0) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.0) (4.10.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0) (1.26.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0) (2.0.11)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.0) (3.7.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.0) (3.1.1)\n",
      "Installing collected packages: wrapt, typing-extensions, tensorflow-estimator, flatbuffers, six, grpcio, absl-py, tensorflow\n",
      "  Attempting uninstall: wrapt\n",
      "    Found existing installation: wrapt 1.13.3\n",
      "    Uninstalling wrapt-1.13.3:\n",
      "      Successfully uninstalled wrapt-1.13.3\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.0.1\n",
      "    Uninstalling typing_extensions-4.0.1:\n",
      "      Successfully uninstalled typing_extensions-4.0.1\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.7.0\n",
      "    Uninstalling tensorflow-estimator-2.7.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.7.0\n",
      "  Attempting uninstall: flatbuffers\n",
      "    Found existing installation: flatbuffers 2.0\n",
      "    Uninstalling flatbuffers-2.0:\n",
      "      Successfully uninstalled flatbuffers-2.0\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.16.0\n",
      "    Uninstalling six-1.16.0:\n",
      "      Successfully uninstalled six-1.16.0\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.43.0\n",
      "    Uninstalling grpcio-1.43.0:\n",
      "      Successfully uninstalled grpcio-1.43.0\n",
      "  Attempting uninstall: absl-py\n",
      "    Found existing installation: absl-py 1.0.0\n",
      "    Uninstalling absl-py-1.0.0:\n",
      "      Successfully uninstalled absl-py-1.0.0\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.8.0\n",
      "    Uninstalling tensorflow-2.8.0:\n",
      "      Successfully uninstalled tensorflow-2.8.0\n",
      "Successfully installed absl-py-0.15.0 flatbuffers-1.12 grpcio-1.32.0 six-1.15.0 tensorflow-2.4.0 tensorflow-estimator-2.4.0 typing-extensions-3.7.4.3 wrapt-1.12.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    WARNING: Ignoring invalid distribution -illow (c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -illow (c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -illow (c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -illow (c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -illow (c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -illow (c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-gpu 2.3.1 requires numpy<1.19.0,>=1.16.0, but you have numpy 1.19.3 which is incompatible.\n",
      "pylint 2.12.2 requires typing-extensions>=3.10.0; python_version < \"3.10\", but you have typing-extensions 3.7.4.3 which is incompatible.\n",
      "black 22.1.0 requires typing-extensions>=3.10.0.0; python_version < \"3.10\", but you have typing-extensions 3.7.4.3 which is incompatible.\n",
      "astroid 2.9.3 requires typing-extensions>=3.10; python_version < \"3.10\", but you have typing-extensions 3.7.4.3 which is incompatible.\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\mtapi\\onedrive\\documents\\brown\\cs1430\\cs1430_env\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3 — Initiate your detection model training\n",
    "## To ensure that our trained custom models have better detection accuracy, we will be using transfer learning from a pre-trained YOLOv3 model in the training. ImageAI provides the option to train with and without transfer learning. I will strongly recommend you use transfer learning except you have thousands of object samples in your dataset.\n",
    "### Download the pre-trained YOLOv3 model \n",
    "#### MAKE SURE NOTE TO save in repo because you will have issues!!!!\n",
    "\n",
    "#!wget https://github.com/OlafenwaMoses/ImageAI/releases/download/essential-v4/pretrained-yolov3.h5\n",
    "\n",
    "#this gives me an error becaue I dont have wget in my PATH correctly config'd, so I did this download manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from imageai.Detection.Custom import DetectionModelTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main_dir = \"..\\data\"\n",
    "data_directory = '..\\data'\n",
    "object_names_array = \"frisbee\"\n",
    "train_from_pretrained_model = \"..\\..\\pretrained-yolov3.h5\" #this is unique to you because it cannot be on the repo!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating anchor boxes for training images and annotation...\n",
      "Average IOU for 9 anchors: 0.95\n",
      "Anchor Boxes generated.\n",
      "Detection configuration saved in  C:/Users/mtapi/OneDrive/Documents/Brown/cs1430/cv_final_proj/data\\json\\detection_config.json\n",
      "Evaluating over 3 samples taken as 20.00% of the training set given at C:/Users/mtapi/OneDrive/Documents/Brown/cs1430/cv_final_proj/data\\train\n",
      "Training over 13 samples  given at C:/Users/mtapi/OneDrive/Documents/Brown/cs1430/cv_final_proj/data\\train\n",
      "Training on: \t['frisbee']\n",
      "Training with Batch Size:  4\n",
      "Number of Training Samples:  13\n",
      "Number of Validation Samples:  3\n",
      "Number of Experiments:  100\n",
      "Training with transfer learning from pretrained Model\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtapi\\OneDrive\\Documents\\Brown\\cs1430\\cs1430_env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layer YoloLayer has arguments in `__init__` and therefore must override `get_config`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtapi\\OneDrive\\Documents\\Brown\\cs1430\\cs1430_env\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:3503: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "32/32 [==============================] - 240s 7s/step - loss: 133.1015 - yolo_layer_loss: 19.3396 - yolo_layer_1_loss: 37.2611 - yolo_layer_2_loss: 64.9276 - val_loss: 92.0098 - val_yolo_layer_loss: 16.2436 - val_yolo_layer_1_loss: 34.5574 - val_yolo_layer_2_loss: 29.6354\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 249s 8s/step - loss: 70.0795 - yolo_layer_loss: 8.1934 - yolo_layer_1_loss: 18.9140 - yolo_layer_2_loss: 31.3990 - val_loss: 73.3463 - val_yolo_layer_loss: 9.4323 - val_yolo_layer_1_loss: 22.8492 - val_yolo_layer_2_loss: 29.4927\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 262s 8s/step - loss: 47.2693 - yolo_layer_loss: 5.3024 - yolo_layer_1_loss: 13.4999 - yolo_layer_2_loss: 16.8955 - val_loss: 50.3283 - val_yolo_layer_loss: 4.2875 - val_yolo_layer_1_loss: 16.3234 - val_yolo_layer_2_loss: 18.1499\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 191s 6s/step - loss: 39.4369 - yolo_layer_loss: 3.7685 - yolo_layer_1_loss: 11.3935 - yolo_layer_2_loss: 12.7089 - val_loss: 37.2403 - val_yolo_layer_loss: 2.5852 - val_yolo_layer_1_loss: 11.6532 - val_yolo_layer_2_loss: 11.4417\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 188s 6s/step - loss: 36.1364 - yolo_layer_loss: 2.7082 - yolo_layer_1_loss: 11.1763 - yolo_layer_2_loss: 10.6940 - val_loss: 29.0241 - val_yolo_layer_loss: 1.2332 - val_yolo_layer_1_loss: 8.5992 - val_yolo_layer_2_loss: 7.6433\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 173s 5s/step - loss: 30.6189 - yolo_layer_loss: 2.0887 - yolo_layer_1_loss: 9.5765 - yolo_layer_2_loss: 7.4104 - val_loss: 22.6470 - val_yolo_layer_loss: 0.3577 - val_yolo_layer_1_loss: 6.6682 - val_yolo_layer_2_loss: 4.0955\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 186s 6s/step - loss: 27.3626 - yolo_layer_loss: 1.8181 - yolo_layer_1_loss: 8.1671 - yolo_layer_2_loss: 5.8659 - val_loss: 20.9550 - val_yolo_layer_loss: 0.1460 - val_yolo_layer_1_loss: 5.9700 - val_yolo_layer_2_loss: 3.3781\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 180s 6s/step - loss: 24.9373 - yolo_layer_loss: 1.3270 - yolo_layer_1_loss: 8.2542 - yolo_layer_2_loss: 3.9215 - val_loss: 19.7546 - val_yolo_layer_loss: 0.2340 - val_yolo_layer_1_loss: 5.7561 - val_yolo_layer_2_loss: 2.4432\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 200s 6s/step - loss: 22.6612 - yolo_layer_loss: 1.0318 - yolo_layer_1_loss: 7.6227 - yolo_layer_2_loss: 2.7341 - val_loss: 18.2908 - val_yolo_layer_loss: 0.0633 - val_yolo_layer_1_loss: 5.3650 - val_yolo_layer_2_loss: 1.7267\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 159s 5s/step - loss: 20.6405 - yolo_layer_loss: 0.6565 - yolo_layer_1_loss: 7.1529 - yolo_layer_2_loss: 1.7527 - val_loss: 16.3342 - val_yolo_layer_loss: 0.0038 - val_yolo_layer_1_loss: 4.4898 - val_yolo_layer_2_loss: 0.9494\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 203s 6s/step - loss: 22.7400 - yolo_layer_loss: 3.0170 - yolo_layer_1_loss: 7.1367 - yolo_layer_2_loss: 1.7534 - val_loss: 16.9444 - val_yolo_layer_loss: 0.0238 - val_yolo_layer_1_loss: 5.3289 - val_yolo_layer_2_loss: 0.9220\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 1743s 56s/step - loss: 19.4895 - yolo_layer_loss: 0.4859 - yolo_layer_1_loss: 7.3371 - yolo_layer_2_loss: 1.0692 - val_loss: 16.4738 - val_yolo_layer_loss: 0.0167 - val_yolo_layer_1_loss: 5.4071 - val_yolo_layer_2_loss: 0.6843\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 220s 7s/step - loss: 19.1522 - yolo_layer_loss: 1.3928 - yolo_layer_1_loss: 6.6834 - yolo_layer_2_loss: 0.7900 - val_loss: 14.6221 - val_yolo_layer_loss: 0.0153 - val_yolo_layer_1_loss: 4.1949 - val_yolo_layer_2_loss: 0.3639\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 226s 7s/step - loss: 18.8080 - yolo_layer_loss: 1.5976 - yolo_layer_1_loss: 6.5899 - yolo_layer_2_loss: 0.6323 - val_loss: 15.0867 - val_yolo_layer_loss: 0.0020 - val_yolo_layer_1_loss: 4.9046 - val_yolo_layer_2_loss: 0.3654\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 204s 6s/step - loss: 17.6706 - yolo_layer_loss: 0.9885 - yolo_layer_1_loss: 6.4897 - yolo_layer_2_loss: 0.4349 - val_loss: 14.1595 - val_yolo_layer_loss: 7.5068e-04 - val_yolo_layer_1_loss: 4.3097 - val_yolo_layer_2_loss: 0.2545\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 157s 5s/step - loss: 19.5008 - yolo_layer_loss: 3.0239 - yolo_layer_1_loss: 6.5774 - yolo_layer_2_loss: 0.3493 - val_loss: 14.2832 - val_yolo_layer_loss: 0.0082 - val_yolo_layer_1_loss: 4.7067 - val_yolo_layer_2_loss: 0.1999\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 245s 8s/step - loss: 18.6449 - yolo_layer_loss: 2.4164 - yolo_layer_1_loss: 6.6748 - yolo_layer_2_loss: 0.2517 - val_loss: 13.3801 - val_yolo_layer_loss: 8.1776e-04 - val_yolo_layer_1_loss: 4.1675 - val_yolo_layer_2_loss: 0.1323\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 232s 7s/step - loss: 17.9535 - yolo_layer_loss: 2.3752 - yolo_layer_1_loss: 6.3865 - yolo_layer_2_loss: 0.1710 - val_loss: 13.8062 - val_yolo_layer_loss: 0.0010 - val_yolo_layer_1_loss: 4.0732 - val_yolo_layer_2_loss: 0.8892\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 192s 6s/step - loss: 16.9129 - yolo_layer_loss: 1.0743 - yolo_layer_1_loss: 6.8704 - yolo_layer_2_loss: 0.1317 - val_loss: 12.6746 - val_yolo_layer_loss: 0.0182 - val_yolo_layer_1_loss: 3.7427 - val_yolo_layer_2_loss: 0.0962\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 177s 6s/step - loss: 15.8743 - yolo_layer_loss: 0.5364 - yolo_layer_1_loss: 6.4133 - yolo_layer_2_loss: 0.1136 - val_loss: 12.5177 - val_yolo_layer_loss: 0.0152 - val_yolo_layer_1_loss: 3.6227 - val_yolo_layer_2_loss: 0.0883\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 189s 6s/step - loss: 16.4756 - yolo_layer_loss: 1.4807 - yolo_layer_1_loss: 6.0920 - yolo_layer_2_loss: 0.1179 - val_loss: 12.3608 - val_yolo_layer_loss: 0.0112 - val_yolo_layer_1_loss: 3.3959 - val_yolo_layer_2_loss: 0.1888\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 175s 6s/step - loss: 15.7873 - yolo_layer_loss: 1.1882 - yolo_layer_1_loss: 5.7341 - yolo_layer_2_loss: 0.1062 - val_loss: 11.7082 - val_yolo_layer_loss: 0.0084 - val_yolo_layer_1_loss: 2.6827 - val_yolo_layer_2_loss: 0.2768\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 170s 5s/step - loss: 16.5436 - yolo_layer_loss: 1.7156 - yolo_layer_1_loss: 5.9783 - yolo_layer_2_loss: 0.1098 - val_loss: 11.2986 - val_yolo_layer_loss: 0.0059 - val_yolo_layer_1_loss: 2.5009 - val_yolo_layer_2_loss: 0.0539\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 177s 6s/step - loss: 14.9866 - yolo_layer_loss: 0.4892 - yolo_layer_1_loss: 5.6617 - yolo_layer_2_loss: 0.0985 - val_loss: 11.3397 - val_yolo_layer_loss: 0.0043 - val_yolo_layer_1_loss: 2.5585 - val_yolo_layer_2_loss: 0.0419\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 178s 6s/step - loss: 14.8604 - yolo_layer_loss: 0.6634 - yolo_layer_1_loss: 5.3642 - yolo_layer_2_loss: 0.0986 - val_loss: 11.2398 - val_yolo_layer_loss: 0.0018 - val_yolo_layer_1_loss: 2.4492 - val_yolo_layer_2_loss: 0.0565\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 597s 19s/step - loss: 15.9421 - yolo_layer_loss: 1.8367 - yolo_layer_1_loss: 5.2671 - yolo_layer_2_loss: 0.1068 - val_loss: 11.1534 - val_yolo_layer_loss: 8.1483e-04 - val_yolo_layer_1_loss: 2.3790 - val_yolo_layer_2_loss: 0.0438\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 217s 7s/step - loss: 15.6338 - yolo_layer_loss: 1.0242 - yolo_layer_1_loss: 5.7765 - yolo_layer_2_loss: 0.1035 - val_loss: 10.7111 - val_yolo_layer_loss: 4.4416e-04 - val_yolo_layer_1_loss: 1.9326 - val_yolo_layer_2_loss: 0.0486\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 264s 8s/step - loss: 16.5992 - yolo_layer_loss: 1.9335 - yolo_layer_1_loss: 5.8153 - yolo_layer_2_loss: 0.1210 - val_loss: 11.8002 - val_yolo_layer_loss: 2.3756e-04 - val_yolo_layer_1_loss: 2.7410 - val_yolo_layer_2_loss: 0.3297\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 265s 8s/step - loss: 15.9498 - yolo_layer_loss: 1.2480 - yolo_layer_1_loss: 5.8662 - yolo_layer_2_loss: 0.1063 - val_loss: 12.4780 - val_yolo_layer_loss: 1.4500e-04 - val_yolo_layer_1_loss: 3.1664 - val_yolo_layer_2_loss: 0.5823\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 181s 6s/step - loss: 15.4859 - yolo_layer_loss: 0.7829 - yolo_layer_1_loss: 5.8708 - yolo_layer_2_loss: 0.1031 - val_loss: 11.7277 - val_yolo_layer_loss: 7.4844e-05 - val_yolo_layer_1_loss: 2.9505 - val_yolo_layer_2_loss: 0.0479\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 220s 7s/step - loss: 16.3217 - yolo_layer_loss: 1.7867 - yolo_layer_1_loss: 5.6863 - yolo_layer_2_loss: 0.1196 - val_loss: 11.6416 - val_yolo_layer_loss: 5.4852e-05 - val_yolo_layer_1_loss: 2.8605 - val_yolo_layer_2_loss: 0.0519\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 189s 6s/step - loss: 15.5606 - yolo_layer_loss: 0.8362 - yolo_layer_1_loss: 5.8914 - yolo_layer_2_loss: 0.1038 - val_loss: 11.5110 - val_yolo_layer_loss: 3.5578e-05 - val_yolo_layer_1_loss: 2.7405 - val_yolo_layer_2_loss: 0.0413\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 193s 6s/step - loss: 16.2620 - yolo_layer_loss: 1.5266 - yolo_layer_1_loss: 5.8987 - yolo_layer_2_loss: 0.1075 - val_loss: 12.6453 - val_yolo_layer_loss: 2.8635e-05 - val_yolo_layer_1_loss: 3.4729 - val_yolo_layer_2_loss: 0.4432\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 179s 6s/step - loss: 15.1474 - yolo_layer_loss: 0.6516 - yolo_layer_1_loss: 5.6654 - yolo_layer_2_loss: 0.1013 - val_loss: 12.2853 - val_yolo_layer_loss: 2.4501e-05 - val_yolo_layer_1_loss: 2.5768 - val_yolo_layer_2_loss: 0.9794\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 213s 7s/step - loss: 16.2379 - yolo_layer_loss: 1.2351 - yolo_layer_1_loss: 6.1546 - yolo_layer_2_loss: 0.1191 - val_loss: 12.5184 - val_yolo_layer_loss: 2.2075e-05 - val_yolo_layer_1_loss: 3.2622 - val_yolo_layer_2_loss: 0.5271\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 195s 6s/step - loss: 16.0428 - yolo_layer_loss: 1.9028 - yolo_layer_1_loss: 5.3032 - yolo_layer_2_loss: 0.1077 - val_loss: 11.4242 - val_yolo_layer_loss: 2.1558e-05 - val_yolo_layer_1_loss: 2.6482 - val_yolo_layer_2_loss: 0.0467\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 190s 6s/step - loss: 15.8265 - yolo_layer_loss: 1.0067 - yolo_layer_1_loss: 5.9852 - yolo_layer_2_loss: 0.1056 - val_loss: 11.8449 - val_yolo_layer_loss: 1.9817e-05 - val_yolo_layer_1_loss: 2.9961 - val_yolo_layer_2_loss: 0.1197\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 10629s 343s/step - loss: 15.8127 - yolo_layer_loss: 1.7949 - yolo_layer_1_loss: 5.1733 - yolo_layer_2_loss: 0.1154 - val_loss: 11.3239 - val_yolo_layer_loss: 1.7191e-05 - val_yolo_layer_1_loss: 2.5457 - val_yolo_layer_2_loss: 0.0491\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 195s 6s/step - loss: 16.9450 - yolo_layer_loss: 2.3041 - yolo_layer_1_loss: 5.7961 - yolo_layer_2_loss: 0.1156 - val_loss: 12.0412 - val_yolo_layer_loss: 1.6696e-05 - val_yolo_layer_1_loss: 2.9670 - val_yolo_layer_2_loss: 0.3450\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 220s 7s/step - loss: 16.6084 - yolo_layer_loss: 1.2878 - yolo_layer_1_loss: 6.4785 - yolo_layer_2_loss: 0.1129 - val_loss: 12.8034 - val_yolo_layer_loss: 0.8228 - val_yolo_layer_1_loss: 3.2005 - val_yolo_layer_2_loss: 0.0509\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 218s 7s/step - loss: 15.5275 - yolo_layer_loss: 0.9998 - yolo_layer_1_loss: 5.6950 - yolo_layer_2_loss: 0.1036 - val_loss: 12.0784 - val_yolo_layer_loss: 1.6851e-05 - val_yolo_layer_1_loss: 3.2654 - val_yolo_layer_2_loss: 0.0838\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 237s 7s/step - loss: 16.1549 - yolo_layer_loss: 1.8764 - yolo_layer_1_loss: 5.4333 - yolo_layer_2_loss: 0.1160 - val_loss: 11.3277 - val_yolo_layer_loss: 1.4692e-05 - val_yolo_layer_1_loss: 2.5226 - val_yolo_layer_2_loss: 0.0760\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - 209s 7s/step - loss: 16.2280 - yolo_layer_loss: 1.7053 - yolo_layer_1_loss: 5.6822 - yolo_layer_2_loss: 0.1113 - val_loss: 11.8863 - val_yolo_layer_loss: 1.4213e-05 - val_yolo_layer_1_loss: 2.4842 - val_yolo_layer_2_loss: 0.6730\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - 217s 7s/step - loss: 15.4848 - yolo_layer_loss: 0.6067 - yolo_layer_1_loss: 6.0310 - yolo_layer_2_loss: 0.1180 - val_loss: 12.1789 - val_yolo_layer_loss: 1.5172e-05 - val_yolo_layer_1_loss: 2.5970 - val_yolo_layer_2_loss: 0.8528\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - 203s 6s/step - loss: 16.3112 - yolo_layer_loss: 1.5562 - yolo_layer_1_loss: 5.9152 - yolo_layer_2_loss: 0.1107 - val_loss: 11.4866 - val_yolo_layer_loss: 1.3408e-05 - val_yolo_layer_1_loss: 2.4459 - val_yolo_layer_2_loss: 0.3115\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - 217s 7s/step - loss: 16.6630 - yolo_layer_loss: 1.8736 - yolo_layer_1_loss: 5.9383 - yolo_layer_2_loss: 0.1219 - val_loss: 11.7620 - val_yolo_layer_loss: 1.3939e-05 - val_yolo_layer_1_loss: 2.3508 - val_yolo_layer_2_loss: 0.6820\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - 188s 6s/step - loss: 17.2673 - yolo_layer_loss: 2.5627 - yolo_layer_1_loss: 5.8629 - yolo_layer_2_loss: 0.1125 - val_loss: 11.3018 - val_yolo_layer_loss: 1.4489e-05 - val_yolo_layer_1_loss: 2.4748 - val_yolo_layer_2_loss: 0.0978\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - 182s 6s/step - loss: 16.4693 - yolo_layer_loss: 1.6009 - yolo_layer_1_loss: 6.0288 - yolo_layer_2_loss: 0.1104 - val_loss: 11.7080 - val_yolo_layer_loss: 1.4734e-05 - val_yolo_layer_1_loss: 2.9209 - val_yolo_layer_2_loss: 0.0580\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - 199s 6s/step - loss: 15.7954 - yolo_layer_loss: 0.9499 - yolo_layer_1_loss: 6.0019 - yolo_layer_2_loss: 0.1145 - val_loss: 12.0849 - val_yolo_layer_loss: 1.4837e-05 - val_yolo_layer_1_loss: 2.5950 - val_yolo_layer_2_loss: 0.7608\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - 55915s 1804s/step - loss: 15.7054 - yolo_layer_loss: 1.2495 - yolo_layer_1_loss: 5.6180 - yolo_layer_2_loss: 0.1088 - val_loss: 12.4625 - val_yolo_layer_loss: 1.3954e-05 - val_yolo_layer_1_loss: 3.6906 - val_yolo_layer_2_loss: 0.0427\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - 185s 6s/step - loss: 15.3335 - yolo_layer_loss: 0.7430 - yolo_layer_1_loss: 5.7579 - yolo_layer_2_loss: 0.1035 - val_loss: 12.1963 - val_yolo_layer_loss: 1.4483e-05 - val_yolo_layer_1_loss: 3.2067 - val_yolo_layer_2_loss: 0.2604\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - 205s 6s/step - loss: 17.4220 - yolo_layer_loss: 2.7101 - yolo_layer_1_loss: 5.8682 - yolo_layer_2_loss: 0.1145 - val_loss: 11.4495 - val_yolo_layer_loss: 1.4513e-05 - val_yolo_layer_1_loss: 2.6784 - val_yolo_layer_2_loss: 0.0419\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - 176s 5s/step - loss: 15.7373 - yolo_layer_loss: 1.0893 - yolo_layer_1_loss: 5.8152 - yolo_layer_2_loss: 0.1036 - val_loss: 11.6586 - val_yolo_layer_loss: 1.5045e-05 - val_yolo_layer_1_loss: 2.6045 - val_yolo_layer_2_loss: 0.3250\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - 186s 6s/step - loss: 16.1867 - yolo_layer_loss: 1.6634 - yolo_layer_1_loss: 5.6822 - yolo_layer_2_loss: 0.1119 - val_loss: 11.5905 - val_yolo_layer_loss: 1.4884e-05 - val_yolo_layer_1_loss: 2.3065 - val_yolo_layer_2_loss: 0.5549\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - 208s 7s/step - loss: 16.1267 - yolo_layer_loss: 1.5118 - yolo_layer_1_loss: 5.7662 - yolo_layer_2_loss: 0.1195 - val_loss: 12.7713 - val_yolo_layer_loss: 1.5411e-05 - val_yolo_layer_1_loss: 3.5969 - val_yolo_layer_2_loss: 0.4453\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - 190s 6s/step - loss: 15.8812 - yolo_layer_loss: 0.8168 - yolo_layer_1_loss: 6.2297 - yolo_layer_2_loss: 0.1055 - val_loss: 11.8635 - val_yolo_layer_loss: 1.5558e-05 - val_yolo_layer_1_loss: 3.0664 - val_yolo_layer_2_loss: 0.0679\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - 190s 6s/step - loss: 15.6196 - yolo_layer_loss: 1.1224 - yolo_layer_1_loss: 5.6633 - yolo_layer_2_loss: 0.1047 - val_loss: 11.7685 - val_yolo_layer_loss: 1.3149e-05 - val_yolo_layer_1_loss: 2.8923 - val_yolo_layer_2_loss: 0.1471\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - 190s 6s/step - loss: 15.7571 - yolo_layer_loss: 0.9206 - yolo_layer_1_loss: 5.9976 - yolo_layer_2_loss: 0.1098 - val_loss: 12.0025 - val_yolo_layer_loss: 1.3416e-05 - val_yolo_layer_1_loss: 2.9079 - val_yolo_layer_2_loss: 0.3654\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - 23609s 761s/step - loss: 16.6235 - yolo_layer_loss: 1.8766 - yolo_layer_1_loss: 5.9065 - yolo_layer_2_loss: 0.1112 - val_loss: 12.0168 - val_yolo_layer_loss: 1.3091e-05 - val_yolo_layer_1_loss: 3.2228 - val_yolo_layer_2_loss: 0.0648\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - 233s 7s/step - loss: 16.1252 - yolo_layer_loss: 1.8325 - yolo_layer_1_loss: 5.4580 - yolo_layer_2_loss: 0.1056 - val_loss: 11.5633 - val_yolo_layer_loss: 1.3544e-05 - val_yolo_layer_1_loss: 2.4836 - val_yolo_layer_2_loss: 0.3505\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - 241s 8s/step - loss: 15.4722 - yolo_layer_loss: 0.6956 - yolo_layer_1_loss: 5.9444 - yolo_layer_2_loss: 0.1031 - val_loss: 11.2587 - val_yolo_layer_loss: 1.5216e-05 - val_yolo_layer_1_loss: 2.4761 - val_yolo_layer_2_loss: 0.0534\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - 247s 8s/step - loss: 15.5552 - yolo_layer_loss: 1.1175 - yolo_layer_1_loss: 5.5989 - yolo_layer_2_loss: 0.1096 - val_loss: 10.9777 - val_yolo_layer_loss: 1.3464e-05 - val_yolo_layer_1_loss: 2.2075 - val_yolo_layer_2_loss: 0.0410\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - 257s 8s/step - loss: 17.1749 - yolo_layer_loss: 2.0497 - yolo_layer_1_loss: 6.2816 - yolo_layer_2_loss: 0.1145 - val_loss: 11.9391 - val_yolo_layer_loss: 1.3588e-05 - val_yolo_layer_1_loss: 2.4863 - val_yolo_layer_2_loss: 0.7237\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - 264s 8s/step - loss: 16.3328 - yolo_layer_loss: 1.8300 - yolo_layer_1_loss: 5.6665 - yolo_layer_2_loss: 0.1071 - val_loss: 11.7287 - val_yolo_layer_loss: 1.5666e-05 - val_yolo_layer_1_loss: 2.6027 - val_yolo_layer_2_loss: 0.3968\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - 268s 8s/step - loss: 16.9337 - yolo_layer_loss: 1.9874 - yolo_layer_1_loss: 6.1021 - yolo_layer_2_loss: 0.1151 - val_loss: 11.8958 - val_yolo_layer_loss: 1.3358e-05 - val_yolo_layer_1_loss: 3.0758 - val_yolo_layer_2_loss: 0.0909\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - 216s 7s/step - loss: 14.9918 - yolo_layer_loss: 1.9069e-05 - yolo_layer_1_loss: 6.1670 - yolo_layer_2_loss: 0.0957 - val_loss: 11.3651 - val_yolo_layer_loss: 1.3625e-05 - val_yolo_layer_1_loss: 2.5885 - val_yolo_layer_2_loss: 0.0474\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - 309s 10s/step - loss: 17.0266 - yolo_layer_loss: 2.4805 - yolo_layer_1_loss: 5.6925 - yolo_layer_2_loss: 0.1245 - val_loss: 11.9979 - val_yolo_layer_loss: 1.3824e-05 - val_yolo_layer_1_loss: 3.2121 - val_yolo_layer_2_loss: 0.0566\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - 284s 9s/step - loss: 16.5456 - yolo_layer_loss: 1.6187 - yolo_layer_1_loss: 6.0814 - yolo_layer_2_loss: 0.1164 - val_loss: 11.7821 - val_yolo_layer_loss: 1.4243e-05 - val_yolo_layer_1_loss: 2.5861 - val_yolo_layer_2_loss: 0.4668\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - 240s 7s/step - loss: 16.6738 - yolo_layer_loss: 1.4160 - yolo_layer_1_loss: 6.4200 - yolo_layer_2_loss: 0.1087 - val_loss: 11.4956 - val_yolo_layer_loss: 1.4637e-05 - val_yolo_layer_1_loss: 2.5497 - val_yolo_layer_2_loss: 0.2167\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - 234s 7s/step - loss: 17.2783 - yolo_layer_loss: 2.0810 - yolo_layer_1_loss: 6.3627 - yolo_layer_2_loss: 0.1054 - val_loss: 11.1447 - val_yolo_layer_loss: 1.4538e-05 - val_yolo_layer_1_loss: 2.3663 - val_yolo_layer_2_loss: 0.0493\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - 293s 9s/step - loss: 16.5911 - yolo_layer_loss: 1.9800 - yolo_layer_1_loss: 5.7673 - yolo_layer_2_loss: 0.1146 - val_loss: 12.0515 - val_yolo_layer_loss: 1.4801e-05 - val_yolo_layer_1_loss: 2.7467 - val_yolo_layer_2_loss: 0.5757\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - 209s 7s/step - loss: 15.1562 - yolo_layer_loss: 0.7440 - yolo_layer_1_loss: 5.5777 - yolo_layer_2_loss: 0.1054 - val_loss: 11.8693 - val_yolo_layer_loss: 1.4235e-05 - val_yolo_layer_1_loss: 2.9516 - val_yolo_layer_2_loss: 0.1885\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - 203s 6s/step - loss: 15.4959 - yolo_layer_loss: 0.7508 - yolo_layer_1_loss: 5.9138 - yolo_layer_2_loss: 0.1021 - val_loss: 11.3120 - val_yolo_layer_loss: 1.4993e-05 - val_yolo_layer_1_loss: 2.4973 - val_yolo_layer_2_loss: 0.0856\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - 258s 8s/step - loss: 16.4989 - yolo_layer_loss: 1.6202 - yolo_layer_1_loss: 6.0349 - yolo_layer_2_loss: 0.1146 - val_loss: 12.8257 - val_yolo_layer_loss: 1.4560e-05 - val_yolo_layer_1_loss: 3.8843 - val_yolo_layer_2_loss: 0.2123\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - 263s 8s/step - loss: 15.8413 - yolo_layer_loss: 1.6371 - yolo_layer_1_loss: 5.3751 - yolo_layer_2_loss: 0.0999 - val_loss: 11.3543 - val_yolo_layer_loss: 1.3850e-05 - val_yolo_layer_1_loss: 2.5696 - val_yolo_layer_2_loss: 0.0555\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - 301s 9s/step - loss: 16.2485 - yolo_layer_loss: 1.3194 - yolo_layer_1_loss: 6.0867 - yolo_layer_2_loss: 0.1133 - val_loss: 10.9114 - val_yolo_layer_loss: 1.4822e-05 - val_yolo_layer_1_loss: 2.1319 - val_yolo_layer_2_loss: 0.0504\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - 246s 8s/step - loss: 16.1358 - yolo_layer_loss: 1.4538 - yolo_layer_1_loss: 5.8443 - yolo_layer_2_loss: 0.1086 - val_loss: 11.3686 - val_yolo_layer_loss: 1.4295e-05 - val_yolo_layer_1_loss: 2.2149 - val_yolo_layer_2_loss: 0.4246\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - 233s 7s/step - loss: 16.0087 - yolo_layer_loss: 1.3622 - yolo_layer_1_loss: 5.8048 - yolo_layer_2_loss: 0.1126 - val_loss: 11.7275 - val_yolo_layer_loss: 1.3436e-05 - val_yolo_layer_1_loss: 2.9391 - val_yolo_layer_2_loss: 0.0592\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - 202s 6s/step - loss: 15.4278 - yolo_layer_loss: 0.9083 - yolo_layer_1_loss: 5.6875 - yolo_layer_2_loss: 0.1028 - val_loss: 11.3091 - val_yolo_layer_loss: 1.4621e-05 - val_yolo_layer_1_loss: 2.1382 - val_yolo_layer_2_loss: 0.4418\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - 226s 7s/step - loss: 15.2834 - yolo_layer_loss: 0.6710 - yolo_layer_1_loss: 5.7797 - yolo_layer_2_loss: 0.1034 - val_loss: 12.1144 - val_yolo_layer_loss: 1.5861e-05 - val_yolo_layer_1_loss: 3.3202 - val_yolo_layer_2_loss: 0.0651\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - 197s 6s/step - loss: 16.1851 - yolo_layer_loss: 1.7126 - yolo_layer_1_loss: 5.6391 - yolo_layer_2_loss: 0.1042 - val_loss: 11.1984 - val_yolo_layer_loss: 1.3245e-05 - val_yolo_layer_1_loss: 2.4150 - val_yolo_layer_2_loss: 0.0542\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - 206s 6s/step - loss: 16.4276 - yolo_layer_loss: 1.6446 - yolo_layer_1_loss: 5.9456 - yolo_layer_2_loss: 0.1083 - val_loss: 11.4631 - val_yolo_layer_loss: 1.4253e-05 - val_yolo_layer_1_loss: 2.2397 - val_yolo_layer_2_loss: 0.4943\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - 214s 7s/step - loss: 16.2263 - yolo_layer_loss: 1.2546 - yolo_layer_1_loss: 6.1336 - yolo_layer_2_loss: 0.1090 - val_loss: 12.0479 - val_yolo_layer_loss: 1.4209e-05 - val_yolo_layer_1_loss: 3.1130 - val_yolo_layer_2_loss: 0.2058\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - 256s 8s/step - loss: 14.9121 - yolo_layer_loss: 0.0457 - yolo_layer_1_loss: 6.0320 - yolo_layer_2_loss: 0.1053 - val_loss: 11.8090 - val_yolo_layer_loss: 1.3921e-05 - val_yolo_layer_1_loss: 2.9752 - val_yolo_layer_2_loss: 0.1046\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - 237s 7s/step - loss: 15.6651 - yolo_layer_loss: 1.2401 - yolo_layer_1_loss: 5.5976 - yolo_layer_2_loss: 0.0982 - val_loss: 11.5562 - val_yolo_layer_loss: 1.4079e-05 - val_yolo_layer_1_loss: 2.5495 - val_yolo_layer_2_loss: 0.2776\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - 245s 8s/step - loss: 15.6941 - yolo_layer_loss: 1.3521 - yolo_layer_1_loss: 5.5109 - yolo_layer_2_loss: 0.1020 - val_loss: 12.0545 - val_yolo_layer_loss: 1.3728e-05 - val_yolo_layer_1_loss: 3.2718 - val_yolo_layer_2_loss: 0.0536\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - 202s 6s/step - loss: 15.7442 - yolo_layer_loss: 0.7965 - yolo_layer_1_loss: 6.1121 - yolo_layer_2_loss: 0.1065 - val_loss: 12.1329 - val_yolo_layer_loss: 1.5202e-05 - val_yolo_layer_1_loss: 3.3523 - val_yolo_layer_2_loss: 0.0515\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - 225s 7s/step - loss: 16.0044 - yolo_layer_loss: 1.2657 - yolo_layer_1_loss: 5.9069 - yolo_layer_2_loss: 0.1027 - val_loss: 12.0998 - val_yolo_layer_loss: 1.4532e-05 - val_yolo_layer_1_loss: 2.5748 - val_yolo_layer_2_loss: 0.7958\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - 267s 8s/step - loss: 16.7963 - yolo_layer_loss: 2.0132 - yolo_layer_1_loss: 5.9382 - yolo_layer_2_loss: 0.1158 - val_loss: 12.4531 - val_yolo_layer_loss: 1.6510e-05 - val_yolo_layer_1_loss: 2.7350 - val_yolo_layer_2_loss: 0.9889\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - 260s 8s/step - loss: 17.1598 - yolo_layer_loss: 2.2557 - yolo_layer_1_loss: 6.0581 - yolo_layer_2_loss: 0.1168 - val_loss: 11.5174 - val_yolo_layer_loss: 1.4299e-05 - val_yolo_layer_1_loss: 2.4939 - val_yolo_layer_2_loss: 0.2943\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - 276s 9s/step - loss: 16.6688 - yolo_layer_loss: 1.9791 - yolo_layer_1_loss: 5.8450 - yolo_layer_2_loss: 0.1155 - val_loss: 11.5553 - val_yolo_layer_loss: 1.4372e-05 - val_yolo_layer_1_loss: 2.7506 - val_yolo_layer_2_loss: 0.0756\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - 268s 8s/step - loss: 15.4036 - yolo_layer_loss: 0.5855 - yolo_layer_1_loss: 5.9740 - yolo_layer_2_loss: 0.1150 - val_loss: 11.9360 - val_yolo_layer_loss: 1.4392e-05 - val_yolo_layer_1_loss: 3.1513 - val_yolo_layer_2_loss: 0.0555\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - 231s 7s/step - loss: 16.2152 - yolo_layer_loss: 1.9810 - yolo_layer_1_loss: 5.3908 - yolo_layer_2_loss: 0.1143 - val_loss: 12.9039 - val_yolo_layer_loss: 1.4773e-05 - val_yolo_layer_1_loss: 3.3307 - val_yolo_layer_2_loss: 0.8440\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - 255s 8s/step - loss: 16.0525 - yolo_layer_loss: 1.5972 - yolo_layer_1_loss: 5.6117 - yolo_layer_2_loss: 0.1144 - val_loss: 11.1450 - val_yolo_layer_loss: 1.5164e-05 - val_yolo_layer_1_loss: 2.3263 - val_yolo_layer_2_loss: 0.0895\n",
      "Epoch 95/100\n",
      "32/32 [==============================] - 247s 8s/step - loss: 15.6984 - yolo_layer_loss: 0.9689 - yolo_layer_1_loss: 5.8929 - yolo_layer_2_loss: 0.1074 - val_loss: 11.4793 - val_yolo_layer_loss: 1.5731e-05 - val_yolo_layer_1_loss: 2.6984 - val_yolo_layer_2_loss: 0.0518\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - 240s 7s/step - loss: 16.4894 - yolo_layer_loss: 2.1670 - yolo_layer_1_loss: 5.4880 - yolo_layer_2_loss: 0.1053 - val_loss: 13.0618 - val_yolo_layer_loss: 1.5767e-05 - val_yolo_layer_1_loss: 3.9910 - val_yolo_layer_2_loss: 0.3417\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - 223s 7s/step - loss: 15.2966 - yolo_layer_loss: 0.4505 - yolo_layer_1_loss: 6.0227 - yolo_layer_2_loss: 0.0943 - val_loss: 11.3546 - val_yolo_layer_loss: 1.6416e-05 - val_yolo_layer_1_loss: 2.5871 - val_yolo_layer_2_loss: 0.0383\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - 196s 6s/step - loss: 16.4007 - yolo_layer_loss: 1.7021 - yolo_layer_1_loss: 5.8615 - yolo_layer_2_loss: 0.1080 - val_loss: 12.7646 - val_yolo_layer_loss: 1.5773e-05 - val_yolo_layer_1_loss: 3.1276 - val_yolo_layer_2_loss: 0.9078\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - 207s 6s/step - loss: 16.3933 - yolo_layer_loss: 1.9692 - yolo_layer_1_loss: 5.5753 - yolo_layer_2_loss: 0.1196 - val_loss: 11.4451 - val_yolo_layer_loss: 1.3622e-05 - val_yolo_layer_1_loss: 2.6825 - val_yolo_layer_2_loss: 0.0335\n",
      "Epoch 100/100\n",
      "32/32 [==============================] - 231s 7s/step - loss: 16.2682 - yolo_layer_loss: 1.6354 - yolo_layer_1_loss: 5.7901 - yolo_layer_2_loss: 0.1135 - val_loss: 11.2264 - val_yolo_layer_loss: 1.3141e-05 - val_yolo_layer_1_loss: 2.1204 - val_yolo_layer_2_loss: 0.3769\n"
     ]
    }
   ],
   "source": [
    "trainer = DetectionModelTrainer()\n",
    "trainer.setModelTypeAsYOLOv3()\n",
    "trainer.setDataDirectory(data_directory=data_directory)\n",
    "trainer.setTrainConfig(object_names_array=[object_names_array], batch_size=4, num_experiments=100, train_from_pretrained_model=train_from_pretrained_model)\n",
    "trainer.trainModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Model evaluation....\n",
      "Evaluating over 3 samples taken as 20.00% of the training set given at C:/Users/mtapi/OneDrive/Documents/Brown/cs1430/cv_final_proj/data\\train\n",
      "Training over 13 samples  given at C:/Users/mtapi/OneDrive/Documents/Brown/cs1430/cv_final_proj/data\\train\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model File:  C:/Users/mtapi/OneDrive/Documents/Brown/cs1430/cv_final_proj/data/models\\detection_model-ex-001--loss-0110.047.h5 \n",
      "\n",
      "Evaluation samples:  3\n",
      "Using IoU:  0.5\n",
      "Using Object Threshold:  0.3\n",
      "Using Non-Maximum Suppression:  0.5\n",
      "frisbee: 0.0000\n",
      "mAP: 0.0000\n",
      "===============================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model File:  C:/Users/mtapi/OneDrive/Documents/Brown/cs1430/cv_final_proj/data/models\\detection_model-ex-002--loss-0065.645.h5 \n",
      "\n",
      "Evaluation samples:  3\n",
      "Using IoU:  0.5\n",
      "Using Object Threshold:  0.3\n",
      "Using Non-Maximum Suppression:  0.5\n",
      "frisbee: 0.0000\n",
      "mAP: 0.0000\n",
      "===============================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model File:  C:/Users/mtapi/OneDrive/Documents/Brown/cs1430/cv_final_proj/data/models\\detection_model-ex-003--loss-0045.187.h5 \n",
      "\n",
      "Evaluation samples:  3\n",
      "Using IoU:  0.5\n",
      "Using Object Threshold:  0.3\n",
      "Using Non-Maximum Suppression:  0.5\n",
      "frisbee: 0.0000\n",
      "mAP: 0.0000\n",
      "===============================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model File:  C:/Users/mtapi/OneDrive/Documents/Brown/cs1430/cv_final_proj/data/models\\detection_model-ex-004--loss-0037.427.h5 \n",
      "\n",
      "Evaluation samples:  3\n",
      "Using IoU:  0.5\n",
      "Using Object Threshold:  0.3\n",
      "Using Non-Maximum Suppression:  0.5\n",
      "frisbee: 0.0000\n",
      "mAP: 0.0000\n",
      "===============================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model File:  C:/Users/mtapi/OneDrive/Documents/Brown/cs1430/cv_final_proj/data/models\\detection_model-ex-005--loss-0034.955.h5 \n",
      "\n",
      "Evaluation samples:  3\n",
      "Using IoU:  0.5\n",
      "Using Object Threshold:  0.3\n",
      "Using Non-Maximum Suppression:  0.5\n",
      "frisbee: 0.0000\n",
      "mAP: 0.0000\n",
      "===============================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model File:  C:/Users/mtapi/OneDrive/Documents/Brown/cs1430/cv_final_proj/data/models\\detection_model-ex-006--loss-0029.310.h5 \n",
      "\n",
      "Evaluation samples:  3\n",
      "Using IoU:  0.5\n",
      "Using Object Threshold:  0.3\n",
      "Using Non-Maximum Suppression:  0.5\n",
      "frisbee: 0.0000\n",
      "mAP: 0.0000\n",
      "===============================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model File:  C:/Users/mtapi/OneDrive/Documents/Brown/cs1430/cv_final_proj/data/models\\detection_model-ex-007--loss-0027.677.h5 \n",
      "\n",
      "Evaluation samples:  3\n",
      "Using IoU:  0.5\n",
      "Using Object Threshold:  0.3\n",
      "Using Non-Maximum Suppression:  0.5\n",
      "frisbee: 0.0000\n",
      "mAP: 0.0000\n",
      "===============================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model File:  C:/Users/mtapi/OneDrive/Documents/Brown/cs1430/cv_final_proj/data/models\\detection_model-ex-008--loss-0024.004.h5 \n",
      "\n",
      "Evaluation samples:  3\n",
      "Using IoU:  0.5\n",
      "Using Object Threshold:  0.3\n",
      "Using Non-Maximum Suppression:  0.5\n",
      "frisbee: 0.0000\n",
      "mAP: 0.0000\n",
      "===============================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model File:  C:/Users/mtapi/OneDrive/Documents/Brown/cs1430/cv_final_proj/data/models\\detection_model-ex-009--loss-0023.079.h5 \n",
      "\n",
      "Evaluation samples:  3\n",
      "Using IoU:  0.5\n",
      "Using Object Threshold:  0.3\n",
      "Using Non-Maximum Suppression:  0.5\n",
      "frisbee: 0.0000\n",
      "mAP: 0.0000\n",
      "===============================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model File:  C:/Users/mtapi/OneDrive/Documents/Brown/cs1430/cv_final_proj/data/models\\detection_model-ex-010--loss-0020.816.h5 \n",
      "\n",
      "Evaluation samples:  3\n",
      "Using IoU:  0.5\n",
      "Using Object Threshold:  0.3\n",
      "Using Non-Maximum Suppression:  0.5\n",
      "frisbee: 0.0000\n",
      "mAP: 0.0000\n",
      "===============================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model File:  C:/Users/mtapi/OneDrive/Documents/Brown/cs1430/cv_final_proj/data/models\\detection_model-ex-012--loss-0019.632.h5 \n",
      "\n",
      "Evaluation samples:  3\n",
      "Using IoU:  0.5\n",
      "Using Object Threshold:  0.3\n",
      "Using Non-Maximum Suppression:  0.5\n",
      "frisbee: 0.0000\n",
      "mAP: 0.0000\n",
      "===============================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model File:  C:/Users/mtapi/OneDrive/Documents/Brown/cs1430/cv_final_proj/data/models\\detection_model-ex-013--loss-0019.367.h5 \n",
      "\n",
      "Evaluation samples:  3\n",
      "Using IoU:  0.5\n",
      "Using Object Threshold:  0.3\n",
      "Using Non-Maximum Suppression:  0.5\n",
      "frisbee: 0.0000\n",
      "mAP: 0.0000\n",
      "===============================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model File:  C:/Users/mtapi/OneDrive/Documents/Brown/cs1430/cv_final_proj/data/models\\detection_model-ex-015--loss-0017.678.h5 \n",
      "\n",
      "Evaluation samples:  3\n",
      "Using IoU:  0.5\n",
      "Using Object Threshold:  0.3\n",
      "Using Non-Maximum Suppression:  0.5\n",
      "frisbee: 0.3333\n",
      "mAP: 0.3333\n",
      "===============================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model File:  C:/Users/mtapi/OneDrive/Documents/Brown/cs1430/cv_final_proj/data/models\\detection_model-ex-016--loss-0017.346.h5 \n",
      "\n",
      "Evaluation samples:  3\n",
      "Using IoU:  0.5\n",
      "Using Object Threshold:  0.3\n",
      "Using Non-Maximum Suppression:  0.5\n",
      "frisbee: 0.3333\n",
      "mAP: 0.3333\n",
      "===============================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model File:  C:/Users/mtapi/OneDrive/Documents/Brown/cs1430/cv_final_proj/data/models\\detection_model-ex-019--loss-0017.000.h5 \n",
      "\n",
      "Evaluation samples:  3\n",
      "Using IoU:  0.5\n",
      "Using Object Threshold:  0.3\n",
      "Using Non-Maximum Suppression:  0.5\n",
      "frisbee: 0.0476\n",
      "mAP: 0.0476\n",
      "===============================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model File:  C:/Users/mtapi/OneDrive/Documents/Brown/cs1430/cv_final_proj/data/models\\detection_model-ex-020--loss-0015.770.h5 \n",
      "\n",
      "Evaluation samples:  3\n",
      "Using IoU:  0.5\n",
      "Using Object Threshold:  0.3\n",
      "Using Non-Maximum Suppression:  0.5\n",
      "frisbee: 0.3333\n",
      "mAP: 0.3333\n",
      "===============================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model File:  C:/Users/mtapi/OneDrive/Documents/Brown/cs1430/cv_final_proj/data/models\\detection_model-ex-024--loss-0015.397.h5 \n",
      "\n",
      "Evaluation samples:  3\n",
      "Using IoU:  0.5\n",
      "Using Object Threshold:  0.3\n",
      "Using Non-Maximum Suppression:  0.5\n",
      "frisbee: 0.3333\n",
      "mAP: 0.3333\n",
      "===============================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model File:  C:/Users/mtapi/OneDrive/Documents/Brown/cs1430/cv_final_proj/data/models\\detection_model-ex-041--loss-0015.302.h5 \n",
      "\n",
      "Evaluation samples:  3\n",
      "Using IoU:  0.5\n",
      "Using Object Threshold:  0.3\n",
      "Using Non-Maximum Suppression:  0.5\n",
      "frisbee: 0.3333\n",
      "mAP: 0.3333\n",
      "===============================\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model File:  C:/Users/mtapi/OneDrive/Documents/Brown/cs1430/cv_final_proj/data/models\\detection_model-ex-066--loss-0014.768.h5 \n",
      "\n",
      "Evaluation samples:  3\n",
      "Using IoU:  0.5\n",
      "Using Object Threshold:  0.3\n",
      "Using Non-Maximum Suppression:  0.5\n",
      "frisbee: 0.3333\n",
      "mAP: 0.3333\n",
      "===============================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'model_file': 'C:/Users/mtapi/OneDrive/Documents/Brown/cs1430/cv_final_proj/data/models\\\\detection_model-ex-001--loss-0110.047.h5',\n",
       "  'using_iou': 0.5,\n",
       "  'using_object_threshold': 0.3,\n",
       "  'using_non_maximum_suppression': 0.5,\n",
       "  'average_precision': {'frisbee': 0.0},\n",
       "  'evaluation_samples': 3,\n",
       "  'map': 0.0},\n",
       " {'model_file': 'C:/Users/mtapi/OneDrive/Documents/Brown/cs1430/cv_final_proj/data/models\\\\detection_model-ex-002--loss-0065.645.h5',\n",
       "  'using_iou': 0.5,\n",
       "  'using_object_threshold': 0.3,\n",
       "  'using_non_maximum_suppression': 0.5,\n",
       "  'average_precision': {'frisbee': 0.0},\n",
       "  'evaluation_samples': 3,\n",
       "  'map': 0.0},\n",
       " {'model_file': 'C:/Users/mtapi/OneDrive/Documents/Brown/cs1430/cv_final_proj/data/models\\\\detection_model-ex-003--loss-0045.187.h5',\n",
       "  'using_iou': 0.5,\n",
       "  'using_object_threshold': 0.3,\n",
       "  'using_non_maximum_suppression': 0.5,\n",
       "  'average_precision': {'frisbee': 0.0},\n",
       "  'evaluation_samples': 3,\n",
       "  'map': 0.0},\n",
       " {'model_file': 'C:/Users/mtapi/OneDrive/Documents/Brown/cs1430/cv_final_proj/data/models\\\\detection_model-ex-004--loss-0037.427.h5',\n",
       "  'using_iou': 0.5,\n",
       "  'using_object_threshold': 0.3,\n",
       "  'using_non_maximum_suppression': 0.5,\n",
       "  'average_precision': {'frisbee': 0.0},\n",
       "  'evaluation_samples': 3,\n",
       "  'map': 0.0},\n",
       " {'model_file': 'C:/Users/mtapi/OneDrive/Documents/Brown/cs1430/cv_final_proj/data/models\\\\detection_model-ex-005--loss-0034.955.h5',\n",
       "  'using_iou': 0.5,\n",
       "  'using_object_threshold': 0.3,\n",
       "  'using_non_maximum_suppression': 0.5,\n",
       "  'average_precision': {'frisbee': 0.0},\n",
       "  'evaluation_samples': 3,\n",
       "  'map': 0.0},\n",
       " {'model_file': 'C:/Users/mtapi/OneDrive/Documents/Brown/cs1430/cv_final_proj/data/models\\\\detection_model-ex-006--loss-0029.310.h5',\n",
       "  'using_iou': 0.5,\n",
       "  'using_object_threshold': 0.3,\n",
       "  'using_non_maximum_suppression': 0.5,\n",
       "  'average_precision': {'frisbee': 0.0},\n",
       "  'evaluation_samples': 3,\n",
       "  'map': 0.0},\n",
       " {'model_file': 'C:/Users/mtapi/OneDrive/Documents/Brown/cs1430/cv_final_proj/data/models\\\\detection_model-ex-007--loss-0027.677.h5',\n",
       "  'using_iou': 0.5,\n",
       "  'using_object_threshold': 0.3,\n",
       "  'using_non_maximum_suppression': 0.5,\n",
       "  'average_precision': {'frisbee': 0.0},\n",
       "  'evaluation_samples': 3,\n",
       "  'map': 0.0},\n",
       " {'model_file': 'C:/Users/mtapi/OneDrive/Documents/Brown/cs1430/cv_final_proj/data/models\\\\detection_model-ex-008--loss-0024.004.h5',\n",
       "  'using_iou': 0.5,\n",
       "  'using_object_threshold': 0.3,\n",
       "  'using_non_maximum_suppression': 0.5,\n",
       "  'average_precision': {'frisbee': 0.0},\n",
       "  'evaluation_samples': 3,\n",
       "  'map': 0.0},\n",
       " {'model_file': 'C:/Users/mtapi/OneDrive/Documents/Brown/cs1430/cv_final_proj/data/models\\\\detection_model-ex-009--loss-0023.079.h5',\n",
       "  'using_iou': 0.5,\n",
       "  'using_object_threshold': 0.3,\n",
       "  'using_non_maximum_suppression': 0.5,\n",
       "  'average_precision': {'frisbee': 0.0},\n",
       "  'evaluation_samples': 3,\n",
       "  'map': 0.0},\n",
       " {'model_file': 'C:/Users/mtapi/OneDrive/Documents/Brown/cs1430/cv_final_proj/data/models\\\\detection_model-ex-010--loss-0020.816.h5',\n",
       "  'using_iou': 0.5,\n",
       "  'using_object_threshold': 0.3,\n",
       "  'using_non_maximum_suppression': 0.5,\n",
       "  'average_precision': {'frisbee': 0.0},\n",
       "  'evaluation_samples': 3,\n",
       "  'map': 0.0},\n",
       " {'model_file': 'C:/Users/mtapi/OneDrive/Documents/Brown/cs1430/cv_final_proj/data/models\\\\detection_model-ex-012--loss-0019.632.h5',\n",
       "  'using_iou': 0.5,\n",
       "  'using_object_threshold': 0.3,\n",
       "  'using_non_maximum_suppression': 0.5,\n",
       "  'average_precision': {'frisbee': 0.0},\n",
       "  'evaluation_samples': 3,\n",
       "  'map': 0.0},\n",
       " {'model_file': 'C:/Users/mtapi/OneDrive/Documents/Brown/cs1430/cv_final_proj/data/models\\\\detection_model-ex-013--loss-0019.367.h5',\n",
       "  'using_iou': 0.5,\n",
       "  'using_object_threshold': 0.3,\n",
       "  'using_non_maximum_suppression': 0.5,\n",
       "  'average_precision': {'frisbee': 0.0},\n",
       "  'evaluation_samples': 3,\n",
       "  'map': 0.0},\n",
       " {'model_file': 'C:/Users/mtapi/OneDrive/Documents/Brown/cs1430/cv_final_proj/data/models\\\\detection_model-ex-015--loss-0017.678.h5',\n",
       "  'using_iou': 0.5,\n",
       "  'using_object_threshold': 0.3,\n",
       "  'using_non_maximum_suppression': 0.5,\n",
       "  'average_precision': {'frisbee': 0.3333333333333333},\n",
       "  'evaluation_samples': 3,\n",
       "  'map': 0.3333333333333333},\n",
       " {'model_file': 'C:/Users/mtapi/OneDrive/Documents/Brown/cs1430/cv_final_proj/data/models\\\\detection_model-ex-016--loss-0017.346.h5',\n",
       "  'using_iou': 0.5,\n",
       "  'using_object_threshold': 0.3,\n",
       "  'using_non_maximum_suppression': 0.5,\n",
       "  'average_precision': {'frisbee': 0.3333333333333333},\n",
       "  'evaluation_samples': 3,\n",
       "  'map': 0.3333333333333333},\n",
       " {'model_file': 'C:/Users/mtapi/OneDrive/Documents/Brown/cs1430/cv_final_proj/data/models\\\\detection_model-ex-019--loss-0017.000.h5',\n",
       "  'using_iou': 0.5,\n",
       "  'using_object_threshold': 0.3,\n",
       "  'using_non_maximum_suppression': 0.5,\n",
       "  'average_precision': {'frisbee': 0.047619047619047616},\n",
       "  'evaluation_samples': 3,\n",
       "  'map': 0.047619047619047616},\n",
       " {'model_file': 'C:/Users/mtapi/OneDrive/Documents/Brown/cs1430/cv_final_proj/data/models\\\\detection_model-ex-020--loss-0015.770.h5',\n",
       "  'using_iou': 0.5,\n",
       "  'using_object_threshold': 0.3,\n",
       "  'using_non_maximum_suppression': 0.5,\n",
       "  'average_precision': {'frisbee': 0.3333333333333333},\n",
       "  'evaluation_samples': 3,\n",
       "  'map': 0.3333333333333333},\n",
       " {'model_file': 'C:/Users/mtapi/OneDrive/Documents/Brown/cs1430/cv_final_proj/data/models\\\\detection_model-ex-024--loss-0015.397.h5',\n",
       "  'using_iou': 0.5,\n",
       "  'using_object_threshold': 0.3,\n",
       "  'using_non_maximum_suppression': 0.5,\n",
       "  'average_precision': {'frisbee': 0.3333333333333333},\n",
       "  'evaluation_samples': 3,\n",
       "  'map': 0.3333333333333333},\n",
       " {'model_file': 'C:/Users/mtapi/OneDrive/Documents/Brown/cs1430/cv_final_proj/data/models\\\\detection_model-ex-041--loss-0015.302.h5',\n",
       "  'using_iou': 0.5,\n",
       "  'using_object_threshold': 0.3,\n",
       "  'using_non_maximum_suppression': 0.5,\n",
       "  'average_precision': {'frisbee': 0.3333333333333333},\n",
       "  'evaluation_samples': 3,\n",
       "  'map': 0.3333333333333333},\n",
       " {'model_file': 'C:/Users/mtapi/OneDrive/Documents/Brown/cs1430/cv_final_proj/data/models\\\\detection_model-ex-066--loss-0014.768.h5',\n",
       "  'using_iou': 0.5,\n",
       "  'using_object_threshold': 0.3,\n",
       "  'using_non_maximum_suppression': 0.5,\n",
       "  'average_precision': {'frisbee': 0.3333333333333333},\n",
       "  'evaluation_samples': 3,\n",
       "  'map': 0.3333333333333333}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Evalute the model\n",
    "from imageai.Detection.Custom import DetectionModelTrainer\n",
    "\n",
    "trainer = DetectionModelTrainer()\n",
    "trainer.setModelTypeAsYOLOv3()\n",
    "trainer.setDataDirectory(data_directory=data_directory)\n",
    "trainer.evaluateModel(model_path=data_directory+\"/models\", json_path=data_directory+\"/json/detection_config.json\", iou_threshold=0.5, object_threshold=0.3, nms_threshold=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we test this model out with test data set:\n",
    "from imageai.Detection.Custom import CustomObjectDetection\n",
    "\n",
    "detector = CustomObjectDetection()\n",
    "detector.setModelTypeAsYOLOv3()\n",
    "detector.setModelPath(\".\\data\\models\\detection_model-ex-066--loss-0014.768.h5\") \n",
    "detector.setJsonPath(data_directory+\"/json/detection_config.json\")\n",
    "detector.loadModel()\n",
    "detections = detector.detectObjectsFromImage(input_image=main_dir+\"/data/test/images/8.jpg\", output_image_path=\"./data/test/images/8-detected.jpg\")\n",
    "for detection in detections:\n",
    "    print(detection[\"name\"], \" : \", detection[\"percentage_probability\"], \" : \", detection[\"box_points\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "004e2b65cc26d8c8070b99ff3ca6bf1ddf16e5787046edb4321d784d4e7add6b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 ('cs1430_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
